#!/usr/bin/env python3
"""
vocab_ocr_agent.py

OCR a vocabulary image with a local Ollama Qwen2.5-VL model (via LiteLLMModel)
and convert the extracted YAML into an Anki-ready CSV (anki_cards.csv).

Notes:
 - Requires smolagents with LiteLLM support (pip install "smolagents[litellm]" pyyaml).
 - Ollama server should be running (default http://127.0.0.1:11434).
"""

import yaml
import csv
import re
import os
from smolagents import Tool, CodeAgent, LiteLLMModel

# ========== 1. YAML → Anki Conversion Tool ==========
class YamlToAnkiTool(Tool):
    name = "yaml_to_anki"
    description = "Convert YAML vocabulary entries into an Anki-ready CSV file."

    # The agent expects these attributes on a Tool subclass.
    inputs = {
        "yaml_content": {
            "type": "string",
            "description": "The pure YAML generated by the model."
        }
    }
    # We return a path string to the generated CSV.
    output_type = "string"

    OUTPUT_FILE = "anki_cards.csv"

    def is_proper_name(self, word: str) -> bool:
        return bool(re.match(r'^[A-Z]', str(word).strip()))

    def forward(self, yaml_content: str) -> str:
        """
        Parse YAML text, clean duplicates, write CSV, return absolute path to CSV.
        """
        if not isinstance(yaml_content, str):
            raise RuntimeError("yaml_content must be a string.")

        # Strip possible markdown fences
        yaml_content = yaml_content.strip()
        if yaml_content.startswith("```") and yaml_content.endswith("```"):
            yaml_content = yaml_content[3:-3].strip()

        try:
            data = yaml.safe_load(yaml_content)
        except yaml.YAMLError as e:
            raise RuntimeError(f"❌ YAML error: {e}")

        # Accept single dict or list of dicts
        if isinstance(data, dict):
            data = [data]
        if not isinstance(data, list):
            raise RuntimeError("❌ Parsed YAML is not a list or dict of entries.")

        seen = set()
        cleaned_data = []
        for entry in data:
            if not isinstance(entry, dict):
                continue
            word = str(entry.get("word", "")).strip()
            back = str(entry.get("back", "")).strip()
            tags = str(entry.get("tags", "")).strip()

            if not word:
                continue

            if not self.is_proper_name(word):
                word = word.lower()

            if word.lower() in seen:
                continue
            seen.add(word.lower())

            cleaned_data.append([word, back, tags])

        # Write CSV
        with open(self.OUTPUT_FILE, "w", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(["Word", "Back", "Tags"])
            writer.writerows(cleaned_data)

        return os.path.abspath(self.OUTPUT_FILE)


# ========== 2. OCR Extraction Prompt ==========
OCR_PROMPT = """
I will upload an image containing vocabulary words with their meanings and example sentences.
Do not import any Python libraries for image analysis. You can already see the image. Produce the YAML directly.

Your tasks are:
1. For each vocabulary entry, extract:
   - word: the vocabulary word (lowercase unless it is a personal/proper name, in which case keep original capitalization). If the word is a verb, replace it with the infinitive form.
   - back: 
       * Start with the meaning.
       * If the word has a noun alternative add an explanation of the noun.
       * Then add 2–3 examples, all enclosed in a single bracket ("example sentence", "..."). 
         Examples should be realistic and varied in structure.
   - tags: grammatical category such as "noun", "verb", "adjective", "adverb", etc (could be many tags)

2. If any field is missing, try to infer or improve it:
   - If examples are missing or too few, create new ones (ensure at least 2–3 examples per word).
   - If the meaning can be improved for clarity, do so.
   - If the grammatical tag is unclear, deduce it from the word and context.
   - If the word is a verb, determine and include its infinitive in the back field as described.

3. Output the result as pure YAML with the following rules:
   - Use `-` (dash) for each list item, never `*` or any other symbol.
   - Indent all fields by two spaces under the dash.
   - Do not include Markdown formatting, backticks, or any text outside the YAML.
   - Ensure proper YAML syntax so it can be parsed without errors.

The format must be exactly:

- word: example_word
  back: meaning (infinitive if verb). (_"example one"_) (_"example two"_) (_"example three"_)
  tags: noun

And the output should be in between ``` and ``` (pure YAML only).
"""


# ========== 3. Model Setup ==========
# LiteLLMModel connects with local Ollama when api_base points to ollama serve.
model = LiteLLMModel(
    model_id="ollama_chat/qwen2.5vl:latest",  # adjust tag if you pulled specific tag (e.g., :7b)
    api_base="http://127.0.0.1:11434",
    num_ctx=8192,
)

# ========== 4. Build Agent ==========
# Use verbosity_level (not `verbosity`) — this matches smolagents' API.
agent = CodeAgent(
    tools=[YamlToAnkiTool()],
    model=model,
    max_steps=3,
    verbosity_level=1,   # 0 = silent, 1 = default, 2 = more verbose
    add_base_tools=False
)


# ========== 5. Run Agent on an Image ==========
def process_vocab_image(image_path: str):
    """
    Sends the OCR prompt to the agent. This version passes the image path inline.
    (If you want to upload binary image content to Ollama, see notes below.)
    """
    # simple guard
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"Image not found: {image_path}")

    query = (
        f"{OCR_PROMPT}\n"
        f"Here is the vocabulary image: {image_path}\n"
        f"Please produce PURE YAML (only) following the spec above, then call the tool `yaml_to_anki` with the YAML content."
    )

    # run the agent
    result = agent.run(query)

    # result may include tool call logs; the tool returns the CSV path
    print("Agent run returned:", result)
    print("If parsing succeeded you should have anki_cards.csv in the current directory.")
    return result


if __name__ == "__main__":
    vocab_image = "input/vocabulary_page.png"  # place your scan here
    process_vocab_image(vocab_image)
